{"status":"success","answer":"Aquí tienes una definición técnica detallada de los marcos y técnicas de ingeniería de prompts más avanzados y efectivos, extraídos de las fuentes proporcionadas. Esta estructura está diseñada para la configuración de un agente de IA de alto rendimiento.\n\n### 1. Marcos de Ingeniería de Prompts (Frameworks)\n\nEstos marcos proporcionan estructuras lógicas para guiar el razonamiento y la generación de respuestas del modelo.\n\n#### **CO-STAR** (Context, Objective, Style, Tone, Audience, Response)\nMarco optimizado para generar activos empresariales y contenido de alta conversión al asegurar la alineación estratégica de todos los aspectos de la salida [1].\n*   **Contexto (C):** Proporciona información de fondo esencial para que el modelo entienda el escenario (e.g., \"Redactando para un blog de principiantes\") [1].\n*   **Objetivo (O):** Define la meta sólida y específica que se busca (e.g., \"Persuadir al lector para realizar una compra aportando valor\") [1, 2].\n*   **Estilo (S):** Especifica el estilo de escritura deseado (e.g., \"Experto pero accesible\", \"Simulando a un redactor de clase mundial\") [1].\n*   **Tono (T):** Establece la actitud emocional de la respuesta (e.g., \"Honesto, confiable, sin ser demasiado vendedor\") [1].\n*   **Audiencia (A):** Define a quién va dirigida la respuesta para adaptar la complejidad y el lenguaje (e.g., \"Principiantes en el nicho\") [1].\n*   **Respuesta (R):** Detalla el formato y la estructura exacta de la salida (e.g., Tabla de pros y contras, lista de 5 puntos, formato Markdown) [1].\n\n#### **Chain-of-Thought (CoT) / Cadena de Pensamiento**\nTécnica que mejora el razonamiento en tareas complejas (matemáticas, lógica, planificación) guiando al modelo a descomponer el problema en pasos intermedios antes de dar la respuesta final [3-6].\n*   **Mecanismo:** Fuerza al modelo a procesar paso a paso, haciendo el razonamiento transparente y reduciendo errores [3, 4].\n*   **Activación Zero-Shot:** Añadir la frase **\"Let's think step by step\"** (Pensemos paso a paso) [3, 5, 7].\n*   **Activación Few-Shot:** Proporcionar ejemplos (demostraciones) que incluyan la cadena de razonamiento completa (pregunta -> razonamiento -> respuesta) [3].\n*   **Variante \"Step-Back\":** Pedir al modelo que primero responda una pregunta general sobre conceptos o historia relacionada antes de abordar la tarea específica para activar conocimiento relevante [8].\n*   **Optimización:** Usar una **Temperatura de 0** para maximizar la lógica y reducir la creatividad aleatoria en los pasos [5, 9].\n\n#### **Tree of Thoughts (ToT) / Árbol de Pensamientos**\nGeneralización del CoT que permite explorar múltiples líneas de razonamiento simultáneamente, creando una estructura de árbol donde el modelo puede ramificar, evaluar y retroceder [3, 10-12].\n*   **Estructura:**\n    1.  **Descomposición:** El problema se divide en pasos de pensamiento.\n    2.  **Generación:** El modelo genera múltiples pensamientos candidatos por paso.\n    3.  **Evaluación:** Se evalúa cada estado/pensamiento (mediante un clasificador o voto).\n    4.  **Búsqueda:** Se utiliza búsqueda en anchura (BFS) o profundidad (DFS) para navegar el árbol [3].\n*   **Uso:** Ideal para planificación estratégica, resolución de problemas creativos complejos y toma de decisiones donde el pensamiento lineal es insuficiente [3, 11].\n\n#### **ReAct (Reason + Act)**\nParadigma que permite a los LLMs resolver tareas complejas combinando el razonamiento verbal con la ejecución de acciones (uso de herramientas externas) [3, 13].\n*   **Ciclo de Ejecución:**\n    1.  **Pensamiento:** El modelo razona sobre el estado actual y qué necesita saber.\n    2.  **Acción:** El modelo genera un comando para una herramienta (ej. buscar en Google, ejecutar código Python) [13].\n    3.  **Observación:** La salida de la herramienta se devuelve al modelo.\n    4.  **Repetición:** El ciclo continúa hasta llegar a la respuesta final [13].\n*   **Aplicación:** Crucial para agentes que necesitan información actualizada (más allá de su fecha de corte de entrenamiento) o capacidad de cálculo exacta [13, 14].\n\n---\n\n### 2. Técnicas de Optimización y Ejecución\n\nEstrategias específicas para refinar la interacción y mejorar la precisión.\n\n#### **Self-Consistency (Auto-Consistencia)**\nMejora el CoT generando múltiples cadenas de razonamiento diversas y seleccionando la respuesta final mediante voto mayoritario [3, 15, 16].\n*   **Implementación:** Ejecutar el mismo prompt varias veces con una **Temperatura > 0** (para diversidad) y seleccionar la respuesta que más se repite [3, 16].\n*   **Beneficio:** Aumenta significativamente la robustez en tareas de razonamiento aritmético y lógico [16].\n\n#### **Reflection / Self-Correction (Reflexión)**\nSolicitar al modelo que revise, critique y mejore su propia salida antes de entregarla como final [17, 18].\n*   **Técnica:** Pedir al modelo que busque errores, sesgos o inconsistencias en su respuesta anterior y genere una versión corregida [18].\n*   **Prompt \"Take a Deep Breath\":** Decirle al modelo \"Take a deep breath\" (Toma una respiración profunda) puede mejorar el rendimiento en tareas de razonamiento al simular un momento de pausa reflexiva [17].\n\n#### **Role Prompting / Persona Experta**\nAsignar un rol específico, credenciales y mentalidad al modelo para acceder a nichos de conocimiento y estilos de comunicación específicos [19-21].\n*   **Definición:** \"Actúa como un [Rol Experto] con [X] años de experiencia en [Campo]\".\n*   **Matiz:** \"Me gustaría que respondieras como...\" tiende a generar respuestas más humanizadas que \"Actúa como...\", que puede ser más funcional [19, 20].\n\n#### **Meta-Prompting**\nUsar el LLM para optimizar o generar sus propios prompts, o coordinar múltiples instancias de sí mismo [22, 23].\n*   **Orquestación:** Un \"Meta-Modelo\" descompone una tarea y asigna sub-tareas a modelos \"Expertos\" especializados, luego integra sus respuestas [23].\n*   **APE (Automatic Prompt Engineering):** Tratar la generación de prompts como un problema de optimización, donde el LLM genera variantes de instrucciones y selecciona la mejor basada en una métrica de evaluación [24-26].\n\n#### **Simulación de Memoria de Trabajo**\nTécnica para conversaciones largas donde se instruye explícitamente al modelo a mantener ciertos datos en su \"memoria activa\" [27, 28].\n*   **Prompt:** \"Recuerda estos detalles [Lista] para nuestras conversaciones futuras. Referencia activamente estas restricciones en tus respuestas\" [27, 28].\n\n---\n\n### 3. Parámetros de Configuración del Modelo (Hyperparameters)\n\nAjustes técnicos críticos que controlan la creatividad y determinismo de la salida [9, 29].\n\n*   **Temperatura (Temperature):** Controla la aleatoriedad en la selección de tokens [29].\n    *   **0 - 0.3:** Determinista, lógica, factual. Ideal para CoT, matemáticas, código y extracción de datos [9, 30].\n    *   **0.7 - 1.0:** Creativo, diverso. Ideal para generación de historias, lluvia de ideas y conversaciones variadas [29].\n*   **Top-P (Nucleus Sampling):** Restringe el conjunto de tokens candidatos a aquellos cuya probabilidad acumulada alcanza P [29].\n    *   **Bajo (e.g., 0.1):** Conservador, se apega a las palabras más probables.\n    *   **Alto (e.g., 0.9 - 1.0):** Permite vocabulario más rico y diverso [9].\n*   **Top-K:** Selecciona solo los K tokens con mayor probabilidad individual [29].\n    *   **Top-K Bajo:** Elimina opciones de baja probabilidad (\"long tail\"), haciendo el texto más enfocado [29].\n*   **Interacción:** Generalmente se recomienda ajustar *o* Temperatura *o* Top-P, pero no ambos drásticamente al mismo tiempo [31]. Si la Temperatura es 0, Top-K y Top-P se vuelven irrelevantes (selección \"greedy\") [31].\n\n### 4. Resumen de Implementación para Agente Técnico\n\n| Componente | Configuración Recomendada | Caso de Uso Principal |\n| :--- | :--- | :--- |\n| **Framework** | **CO-STAR** | Generación de contenido, copy, emails, tareas empresariales. |\n| **Framework** | **ReAct / CoT** | Agentes autónomos, resolución de problemas complejos, uso de herramientas. |\n| **Técnica** | **Few-Shot** | Tareas que requieren un formato de salida específico o estilo difícil de describir. |\n| **Técnica** | **Self-Consistency** | Tareas críticas donde la precisión lógica/matemática es prioritaria (usar Temp > 0.5 y múltiples pasadas). |\n| **Parámetro** | **Temp: 0** | Tareas de extracción, clasificación, código y razonamiento estricto. |\n| **Parámetro** | **Temp: 0.7+** | Tareas creativas, brainstorming, escritura de ficción. |","conversation_id":"d71731dc-d681-4ad3-9b14-bbc95c76054c"}